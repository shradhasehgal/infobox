{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from libindic import inexactsearch\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from editdistance import eval as ed\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(translated_infobox , actual_infobox):\n",
    "    inst = inexactsearch.InexactSearch()\n",
    "    markings = defaultdict(list)\n",
    "    all_keys = list(translated_infobox.keys()) + list(actual_infobox.keys())\n",
    "    translated_infobox = { key.strip() : val for key , val in translated_infobox.items()}\n",
    "    actual_infobox = { key.strip() : val for key , val in actual_infobox.items()}\n",
    "\n",
    "    for key in translated_infobox.keys():\n",
    "        for key2 in actual_infobox.keys():\n",
    "            if fuzz.token_sort_ratio(key , key2) >= 80:\n",
    "                if not translated_infobox[key]:\n",
    "                    markings['S'].append(key)\n",
    "                    continue \n",
    "                elif not actual_infobox[key2]:\n",
    "                    continue\n",
    "                skip = False\n",
    "                try :\n",
    "                    for let in actual_infobox[key2]:\n",
    "                        if let in string.ascii_letters:\n",
    "                            skip = True\n",
    "                            break\n",
    "                    val = inst.compare(translated_infobox[key] , actual_infobox[key2])\n",
    "                except :\n",
    "                    skip = False\n",
    "                    val = 0\n",
    "                if skip : continue\n",
    "                if val >= 0.6 :\n",
    "                    markings['C'].append({key : val})\n",
    "                else :\n",
    "                    markings['S'].append({key : val})\n",
    "                break\n",
    "    for key2 in actual_infobox.keys():\n",
    "        for key in translated_infobox.keys():\n",
    "            if fuzz.token_sort_ratio(key , key2) >= 80:\n",
    "                break\n",
    "        else :\n",
    "            markings['D'].append(key2)\n",
    "            \n",
    "    for key in translated_infobox.keys():\n",
    "        for key2 in actual_infobox.keys():\n",
    "            if fuzz.token_sort_ratio(key , key2) >= 80:\n",
    "                break\n",
    "        else :\n",
    "            markings['I'].append(key)\n",
    "    if len(markings['C']) + len(markings['S']) != 0:\n",
    "        precision = len(markings['C']) / (len(markings['C']) + len(markings['S']))\n",
    "    else : precision = 0\n",
    "    if (len(markings['C']) + len(markings['S']) + len(markings['D'])) != 0:\n",
    "        recall = len(markings['C']) / (len(markings['C']) + len(markings['S']) + len(markings['D']))\n",
    "    else : recall = 0\n",
    "    return [precision , recall] , markings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(data):\n",
    "    overall_score = []\n",
    "    list_d = [defaultdict(int) for i in range(3)]\n",
    "    list_i = [defaultdict(int) for i in range(3)]\n",
    "    keys_score = [defaultdict(lambda : defaultdict(int)) for i in range(3)]\n",
    "    keys_match = [defaultdict(int) for i in range(2)]\n",
    "    for ind , entry in enumerate(data) :\n",
    "        cur_score = []\n",
    "        for key , val in entry.items():\n",
    "            for i in range(3):\n",
    "                if not val[-1] : continue\n",
    "                score , markings = get_score(val[2-i] , val[-1])\n",
    "                cur_score.append(score)\n",
    "                for key in markings['D']:\n",
    "                    list_d[i][key]+=1\n",
    "                    keys_score[i][key]['D']+=1\n",
    "                for key in markings['I']:\n",
    "                    list_i[i][key]+=1\n",
    "                    keys_score[i][key]['I']+=1\n",
    "                for label in ['C' , 'S']:\n",
    "                    for item in markings[label]:\n",
    "                        for key2 , val2 in item.items():\n",
    "                            keys_score[i][key][label]+=1\n",
    "                            if val2 >= 0.7 :\n",
    "                                keys_match[0][key2]+=1\n",
    "                            if val2 >= 0.3:\n",
    "                                keys_match[1][key2]+=1\n",
    "        if not cur_score : continue\n",
    "        overall_score.append(np.array(sum(cur_score , [])))\n",
    "#         break\n",
    "    list_d = [ {key : val for key , val in sorted(list_d[i].items() , key = lambda item : item[1] , reverse=True)[:20]} for i in range(3)]\n",
    "    list_i = [ {key : val for key , val in sorted(list_i[i].items() , key = lambda item : item[1] , reverse=True)[:20]} for i in range(3)]\n",
    "    df = pd.DataFrame(overall_score , columns=['M1-Precision','M1-Recall','M2-Precision','M2-Recall','Baseline-Precision','Baseline-Recall'])\n",
    "    for method in keys_score:\n",
    "        for key , val in method.items():\n",
    "            den = val['C'] + val['S']\n",
    "            method[key]['precision'] = val['C'] / (max(1 , den))\n",
    "            den += val['D']\n",
    "            method[key]['recall'] = val['C'] / max(1 , den)\n",
    "    graph_data = {\n",
    "        'list_d' : list_d,\n",
    "        'list_i' : list_i,\n",
    "        'keys_match' : keys_match,\n",
    "        'keys_score' : keys_score\n",
    "    }\n",
    "    return df , graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records for people : 700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M1-Precision          0.482690\n",
       "M1-Recall             0.074289\n",
       "M2-Precision          0.418671\n",
       "M2-Recall             0.183139\n",
       "Baseline-Precision    0.390357\n",
       "Baseline-Recall       0.065681\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "with open('people_eval_records.jsonl') as f:\n",
    "    data = [ json.loads(i) for i in f.readlines()]\n",
    "print(\"Number of records for people :\" , len(data))\n",
    "df , graph_data = get_results(data)\n",
    "display(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records for places : 400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M1-Precision          0.497500\n",
       "M1-Recall             0.018789\n",
       "M2-Precision          0.246628\n",
       "M2-Recall             0.034243\n",
       "Baseline-Precision    0.358750\n",
       "Baseline-Recall       0.012597\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "with open('places_eval_records.jsonl') as f:\n",
    "    data = [ json.loads(i) for i in f.readlines()]\n",
    "print(\"Number of records for places :\" , len(data))\n",
    "df , graph_data = get_results(data)\n",
    "display(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_data = dict with keys [list_d , list_i , keys_match , keys_score ]\n",
    "\n",
    "\n",
    "# For list_d / list_i / keys_score[i]:\n",
    "#     [0] = Method1\n",
    "#     [1] = Method2\n",
    "#     [2] = Baseline\n",
    "#     list_d[i] = dictionary with {count where key in actual infobox but not in our infobox} for each key in decreasing order\n",
    "#     list_i[i] = dictionary with {count where key in our infobox but not in the actual infobox} for each key in decreasing order\n",
    "#     keys_score[i] = dictionary with {precision , recall , C , S , I , D} for each key\n",
    "\n",
    "# For keys_match :\n",
    "#     [0] = match >= 70%\n",
    "#     [1] = match >= 30%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
